{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nQ_gx-4Z7Blv"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# open the CSV file and read its contents into a list\n",
        "train_file = open(\"/content/drive/MyDrive/MNIST/train.csv\", 'r')\n",
        "train_list = train_file.readlines()\n",
        "train_file.close()"
      ],
      "metadata": {
        "id": "WSgRcDJh8EEo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open the CSV file and read its contents into a list\n",
        "test_file = open(\"/content/drive/MyDrive/MNIST/test.csv\", 'r')\n",
        "test_list = test_file.readlines()\n",
        "test_file.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "CUpwWdRw-N5o"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class DNN:\n",
        "  def __init__(self, sizes, epochs, lr):\n",
        "    # taille des couches , nb d iterations epoch , taux d apprentissage lr\n",
        "    self.sizes = sizes\n",
        "    self.epochs = epochs\n",
        "    self.lr = lr\n",
        "\n",
        "    # number of nodes in each layer couche\n",
        "    input_layer=self.sizes[0]\n",
        "    hidden_1=self.sizes[1]\n",
        "    hidden_2=self.sizes[2]\n",
        "    output_layer=self.sizes[3]\n",
        "     # Les fonctions d'activation utilisées sont la fonction sigmoïde pour les couches cachées et la fonction softmax pour la couche de sortie.\n",
        "    self.params = {\n",
        "        'W1':np.random.randn(hidden_1, input_layer) * np.sqrt(1. / hidden_1),\n",
        "        'W2':np.random.randn(hidden_2, hidden_1) * np.sqrt(1. / hidden_2),\n",
        "        'W3':np.random.randn(output_layer, hidden_2) * np.sqrt(1. / output_layer)\n",
        "    }\n",
        "  def sigmoid(self, x, derivative=False):\n",
        "      if derivative:\n",
        "          return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
        "      return 1/(1 + np.exp(-x))\n",
        "\n",
        "  def softmax(self, x, derivative=False):\n",
        "      # Numerically stable with large exponentials\n",
        "      exps = np.exp(x - x.max())\n",
        "      if derivative:\n",
        "          return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
        "      return exps / np.sum(exps, axis=0)\n",
        "\n",
        "      # une propagation avant à travers le réseau pour calculer les activations de chaque couche en fonction des poids actuels.\n",
        "  def forward_pass(self, x_train):\n",
        "      params = self.params\n",
        "\n",
        "      # input layer activations becomes sample\n",
        "      params['A0'] = x_train\n",
        "\n",
        "      # input layer to hidden layer 1\n",
        "      params['Z1'] = np.dot(params[\"W1\"], params['A0'])\n",
        "      params['A1'] = self.sigmoid(params['Z1'])\n",
        "\n",
        "      # hidden layer 1 to hidden layer 2\n",
        "      params['Z2'] = np.dot(params[\"W2\"], params['A1'])\n",
        "      params['A2'] = self.sigmoid(params['Z2'])\n",
        "\n",
        "      # hidden layer 2 to output layer\n",
        "      params['Z3'] = np.dot(params[\"W3\"], params['A2'])\n",
        "      params['A3'] = self.softmax(params['Z3'])\n",
        "\n",
        "      return params['A3']\n",
        "\n",
        "#une rétropropagation de l'erreur à travers le réseau pour calculer les changements nécessaires aux poids afin de minimiser l'erreur\n",
        "  def backward_pass(self, y_train, output):\n",
        "      '''\n",
        "          This is the backpropagation algorithm, for calculating the updates\n",
        "          of the neural network's parameters.\n",
        "\n",
        "          Note: There is a stability issue that causes warnings. This is\n",
        "                caused  by the dot and multiply operations on the huge arrays.\n",
        "\n",
        "                RuntimeWarning: invalid value encountered in true_divide\n",
        "                RuntimeWarning: overflow encountered in exp\n",
        "                RuntimeWarning: overflow encountered in square\n",
        "      '''\n",
        "      params = self.params\n",
        "      change_w = {}\n",
        "\n",
        "      # Calculate W3 update\n",
        "      error = 2 * (output - y_train) / output.shape[0] * self.softmax(params['Z3'], derivative=True)\n",
        "      change_w['W3'] = np.outer(error, params['A2'])\n",
        "\n",
        "      # Calculate W2 update\n",
        "      error = np.dot(params['W3'].T, error) * self.sigmoid(params['Z2'], derivative=True)\n",
        "      change_w['W2'] = np.outer(error, params['A1'])\n",
        "\n",
        "      # Calculate W1 update\n",
        "      error = np.dot(params['W2'].T, error) * self.sigmoid(params['Z1'], derivative=True)\n",
        "      change_w['W1'] = np.outer(error, params['A0'])\n",
        "\n",
        "      return change_w\n",
        "#mise à jour les poids du réseau en utilisant la règle de descente de gradient stochastique.\n",
        "  def update_network_parameters(self, changes_to_w):\n",
        "      '''\n",
        "          Update network parameters according to update rule from\n",
        "          Stochastic Gradient Descent.\n",
        "\n",
        "          θ = θ - η * ∇J(x, y),\n",
        "              theta θ:            a network parameter (e.g. a weight w)\n",
        "              eta η:              the learning rate\n",
        "              gradient ∇J(x, y):  the gradient of the objective function,\n",
        "                                  i.e. the change for a specific theta θ\n",
        "      '''\n",
        "\n",
        "      for key, value in changes_to_w.items():\n",
        "          self.params[key] -= self.lr * value\n",
        "\n",
        "#compute_accuracy calcule la précision du réseau sur un ensemble de données de test en effectuant une propagation\n",
        "# avant et en comparant les prédictions avec les étiquettes réelles.\n",
        "  def compute_accuracy(self, test_data, output_nodes):\n",
        "      '''\n",
        "          This function does a forward pass of x, then checks if the indices\n",
        "          of the maximum value in the output equals the indices in the label\n",
        "          y. Then it sums over each prediction and calculates the accuracy.\n",
        "      '''\n",
        "      predictions = []\n",
        "\n",
        "      for x in train_list:\n",
        "          all_values = x.split(',')\n",
        "          # scale and shift the inputs\n",
        "          inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
        "          # create the target output values (all 0.01, except the desired label which is 0.99)\n",
        "          targets = np.zeros(output_nodes) + 0.01\n",
        "          # all_values[0] is the target label for this record\n",
        "          targets[int(all_values[0])] = 0.99\n",
        "          output = self.forward_pass(inputs)\n",
        "          pred = np.argmax(output)\n",
        "          predictions.append(pred == np.argmax(targets))\n",
        "\n",
        "      return np.mean(predictions)\n",
        "\n",
        "  def train(self, train_list, test_list, output_nodes):\n",
        "      start_time = time.time()\n",
        "      for iteration in range(self.epochs):\n",
        "          for x in train_list:\n",
        "              all_values = x.split(',')\n",
        "              # scale and shift the inputs\n",
        "              inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
        "              # create the target output values (all 0.01, except the desired label which is 0.99)\n",
        "              targets = np.zeros(output_nodes) + 0.01\n",
        "              # all_values[0] is the target label for this record\n",
        "              targets[int(all_values[0])] = 0.99\n",
        "              output = self.forward_pass(inputs)\n",
        "              changes_to_w = self.backward_pass(targets, output)\n",
        "              self.update_network_parameters(changes_to_w)\n",
        "\n",
        "          accuracy = self.compute_accuracy(test_list, output_nodes)\n",
        "          print('Epoch: {0}, Time Spent: {1:.2f}s, Accuracy: {2:.2f}%'.format(\n",
        "              iteration+1, time.time() - start_time, accuracy * 100\n",
        "          ))\n"
      ],
      "metadata": {
        "id": "zxbVa_Uc-kb_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dnn = DNN(sizes=[784, 128, 64, 10], epochs=20, lr=0.001)\n",
        "dnn.train(train_list, test_list, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmUOpHSe-rBd",
        "outputId": "9d73fca2-43f1-4401-cded-2dca288b1bb4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Time Spent: 48.14s, Accuracy: 27.77%\n",
            "Epoch: 2, Time Spent: 97.76s, Accuracy: 40.54%\n",
            "Epoch: 3, Time Spent: 148.57s, Accuracy: 43.24%\n",
            "Epoch: 4, Time Spent: 195.91s, Accuracy: 44.16%\n",
            "Epoch: 5, Time Spent: 244.86s, Accuracy: 44.68%\n",
            "Epoch: 6, Time Spent: 296.25s, Accuracy: 45.43%\n",
            "Epoch: 7, Time Spent: 344.49s, Accuracy: 46.61%\n",
            "Epoch: 8, Time Spent: 392.85s, Accuracy: 47.70%\n",
            "Epoch: 9, Time Spent: 442.35s, Accuracy: 48.65%\n",
            "Epoch: 10, Time Spent: 493.16s, Accuracy: 49.48%\n",
            "Epoch: 11, Time Spent: 541.39s, Accuracy: 50.28%\n",
            "Epoch: 12, Time Spent: 590.58s, Accuracy: 51.08%\n",
            "Epoch: 13, Time Spent: 641.45s, Accuracy: 51.85%\n",
            "Epoch: 14, Time Spent: 690.98s, Accuracy: 52.68%\n",
            "Epoch: 15, Time Spent: 739.42s, Accuracy: 53.52%\n",
            "Epoch: 16, Time Spent: 788.22s, Accuracy: 54.40%\n",
            "Epoch: 17, Time Spent: 839.59s, Accuracy: 55.32%\n",
            "Epoch: 18, Time Spent: 889.23s, Accuracy: 56.36%\n",
            "Epoch: 19, Time Spent: 938.26s, Accuracy: 57.37%\n",
            "Epoch: 20, Time Spent: 988.01s, Accuracy: 58.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "a0I-Aqb7LRI-",
        "outputId": "7cfbc686-c718-44b9-a1eb-c8280b5c5177",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ]
}