{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aKPcMO2iGjdm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris = pd.read_csv(\"/content/drive/MyDrive/Iris.csv\")\n",
        "iris = iris.sample(frac=1).reset_index(drop=True) # Shuffle\n",
        "X = iris[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
        "X = np.array(X)\n"
      ],
      "metadata": {
        "id": "KnN37-NxHcrf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UoeX1zMrAatT",
        "outputId": "d0ace9be-3ca8-4014-c791-3f693b3e2397",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "Y = iris.Species\n",
        "Y = one_hot_encoder.fit_transform(np.array(Y).reshape(-1, 1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xF4ev0QDHyZy",
        "outputId": "111638d0-97a8-4045-b348-f00e629b18bb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15)\n"
      ],
      "metadata": {
        "id": "B8mLdaqaH0ZV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def NeuralNetwork(X_train, Y_train, epochs, nodes=[], lr=0.15):\n",
        "    hidden_layers = len(nodes) - 1\n",
        "    weights = InitializeWeights(nodes)\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        weights = Train(X_train, Y_train, lr, weights)\n",
        "\n",
        "        if(epoch % 20 == 0):\n",
        "            print(\"Epoch {}\".format(epoch))\n",
        "            print(\"Training Accuracy:{}\".format(Accuracy(X_train, Y_train, weights)))\n",
        "\n",
        "\n",
        "    return weights"
      ],
      "metadata": {
        "id": "oLBW9JGPH418"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def InitializeWeights(nodes):\n",
        "    \"\"\"Initialize weights with random values in [-1, 1] (including bias)\"\"\"\n",
        "    layers, weights = len(nodes), []\n",
        "\n",
        "    for i in range(1, layers):\n",
        "        w = [[np.random.uniform(-1, 1) for k in range(nodes[i-1] + 1)]\n",
        "              for j in range(nodes[i])]\n",
        "        weights.append(np.matrix(w))\n",
        "\n",
        "    return weights"
      ],
      "metadata": {
        "id": "rOrCbHSeIGmi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ForwardPropagation(x, weights, layers):\n",
        "    activations, layer_input = [x], x\n",
        "    for j in range(layers):\n",
        "        activation = Sigmoid(np.dot(layer_input, weights[j].T))\n",
        "        activations.append(activation)\n",
        "        layer_input = np.append(1, activation) # Augment with bias\n",
        "\n",
        "    return activations"
      ],
      "metadata": {
        "id": "oEJt3jNQIJBg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def BackPropagation(y, activations, weights, layers):\n",
        "    outputFinal = activations[-1]\n",
        "    error = np.matrix(y - outputFinal) # Error at output\n",
        "\n",
        "    for j in range(layers, 0, -1):\n",
        "        currActivation = activations[j]\n",
        "\n",
        "        if(j > 1):\n",
        "            # Augment previous activation\n",
        "            prevActivation = np.append(1, activations[j-1])\n",
        "        else:\n",
        "            # First hidden layer, prevActivation is input (without bias)\n",
        "            prevActivation = activations[0]\n",
        "\n",
        "        delta = np.multiply(error, SigmoidDerivative(currActivation))\n",
        "        weights[j-1] += lr * np.multiply(delta.T, prevActivation)\n",
        "\n",
        "        w = np.delete(weights[j-1], [0], axis=1) # Remove bias from weights\n",
        "        error = np.dot(delta, w) # Calculate error for current layer\n",
        "\n",
        "    return weights"
      ],
      "metadata": {
        "id": "nXd_y6WDIPqo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Train(X, Y, lr, weights):\n",
        "    layers = len(weights)\n",
        "    for i in range(len(X)):\n",
        "        x, y = X[i], Y[i]\n",
        "        x = np.matrix(np.append(1, x)) # Augment feature vector\n",
        "\n",
        "        activations = ForwardPropagation(x, weights, layers)\n",
        "        weights = BackPropagation(y, activations, weights, layers)\n",
        "\n",
        "    return weights"
      ],
      "metadata": {
        "id": "5b34r8eHIRUb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def SigmoidDerivative(x):\n",
        "    return np.multiply(x, 1-x)"
      ],
      "metadata": {
        "id": "uWStm1MEIV7g"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Predict(item, weights):\n",
        "    layers = len(weights)\n",
        "    item = np.append(1, item) # Augment feature vector\n",
        "\n",
        "    ##_Forward Propagation_##\n",
        "    activations = ForwardPropagation(item, weights, layers)\n",
        "\n",
        "    outputFinal = activations[-1].A1\n",
        "    index = FindMaxActivation(outputFinal)\n",
        "\n",
        "    # Initialize prediction vector to zeros\n",
        "    y = [0 for i in range(len(outputFinal))]\n",
        "    y[index] = 1  # Set guessed class to 1\n",
        "\n",
        "    return y # Return prediction vector\n",
        "\n",
        "\n",
        "def FindMaxActivation(output):\n",
        "    \"\"\"Find max activation in output\"\"\"\n",
        "    m, index = output[0], 0\n",
        "    for i in range(1, len(output)):\n",
        "        if(output[i] > m):\n",
        "            m, index = output[i], i\n",
        "\n",
        "    return index"
      ],
      "metadata": {
        "id": "YXh-EsDpIXZH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Accuracy(X, Y, weights):\n",
        "    \"\"\"Run set through network, find overall accuracy\"\"\"\n",
        "    correct = 0\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        x, y = X[i], list(Y[i])\n",
        "        guess = Predict(x, weights)\n",
        "\n",
        "        if(y == guess):\n",
        "            # Guessed correctly\n",
        "            correct += 1\n",
        "\n",
        "    return correct / len(X)"
      ],
      "metadata": {
        "id": "9apedQeuIbPJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = len(X[0]) # Number of features\n",
        "o = len(Y[0]) # Number of outputs / classes\n",
        "\n",
        "layers = [f, 5, 10, o] # Number of nodes in layers\n",
        "lr, epochs = 0.15, 100\n",
        "\n",
        "weights = NeuralNetwork(X_train, Y_train, epochs=epochs, nodes=layers, lr=lr);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbvSQai0IhAv",
        "outputId": "986b62cf-c07e-41c6-c767-8aa05a67e771"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20\n",
            "Training Accuracy:0.952755905511811\n",
            "Epoch 40\n",
            "Training Accuracy:0.8346456692913385\n",
            "Epoch 60\n",
            "Training Accuracy:0.905511811023622\n",
            "Epoch 80\n",
            "Training Accuracy:0.8661417322834646\n",
            "Epoch 100\n",
            "Training Accuracy:0.9212598425196851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Testing Accuracy: {}\".format(Accuracy(X_test, Y_test, weights)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C_R0tY_IrBB",
        "outputId": "8f6b4bdf-4cd3-4715-bc3d-935ef04aea99"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}